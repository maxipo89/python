import requests
from bs4 import BeautifulSoup
from requests import get
import re
import csv
headers = {'User-Agent': 'Mozilla/5.0'}
URL = 'https://www.goodreads.com/author/quotes/1455.Ernest_Hemingway'
response = requests.get(f'{URL}', headers=headers)
soup = BeautifulSoup(response.text, 'html.parser')
last_page = soup.select_one('a:nth-child(13)')

if last_page:
    last_page = last_page.getText().strip()
    print (last_page)

start = int(1)
end = int(last_page)

def parse_page(number):
    print(f'Pracuje nad stroną numer {number}.')
    page = get(f'{URL}?page={number}')
    bs = BeautifulSoup(page.content, 'html.parser')
    lis = []
    for quotes in bs.find_all('div', class_='quote'):
        quote = quotes.find('div', class_='quoteText').get_text().strip()
        quote = re.sub("  +", "", quote.replace("\n", ""))
        sign = int(re.search("―", quote).start())
        quote=quote[1:sign-1]


        with open('quotes.csv', 'w', newline='', encoding="utf-8") as file:
            lis.append(quote)
            spamwriter = csv.writer(file)
            for l in lis:
                spamwriter.writerow([l])
for page in range(start, end):
    parse_page(page)

