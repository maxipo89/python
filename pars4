import requests
from bs4 import BeautifulSoup
from requests import get
import sqlite3
import re

headers = {'User-Agent': 'Mozilla/5.0'}
URL = 'https://www.olx.pl/nieruchomosci/mieszkania/sprzedaz/lodzkie/?search%5Bfilter_enum_rooms%5D%5B0%5D=three'
response = requests.get(f'{URL}', headers=headers)

soup = BeautifulSoup(response.text, 'lxml')

for last_page in soup.findAll('a', attrs={'href': re.compile("^https://")},
                              class_='block br3 brc8 large tdnone lheight24'): pass
if last_page:
    last_page = last_page.getText().strip()
    x = 1
    y = last_page
    x = int(x)
    y = int(y)
###
def parse_price(price):
    return float(price.replace(' ', '').replace('zł', '').replace(',', '.'))

def parse_page(number):
    print(f'Pracuje nad stroną numer {number}.')
    page = get(f'{URL}&page={number}')
    bs = BeautifulSoup(page.content, 'html.parser')
    offer: object
    for offer in bs.find_all('div', class_='offer-wrapper'):
        footer = offer.find('td', class_='bottom-cell')
        location = footer.find('small', class_='breadcrumb').get_text().strip().split(',')[0]
        title = offer.find('strong').get_text().strip()
        price = parse_price(offer.find('p', class_='price').get_text().strip())
        link = offer.find('a').get('href').strip()
        cursor.execute('INSERT INTO offers VALUES (?, ?, ?, ?)', (title, price, location, link))
    db.commit()

db = sqlite3.connect('dane.db')
cursor = db.cursor()
print('Połączono z SQLite')
cursor.execute('''CREATE TABLE IF NOT EXISTS offers (name TEXT, price REAL, city TEXT, link TEXT)''')

for page in range(1, 2):
    parse_page(page)

db.close()


#########

db = sqlite3.connect('dane.db')
cursor = db.cursor()
print('Połączono z SQLite')
t = ('%olx%',)
cursor.execute('SELECT link FROM offers WHERE link LIKE ? ', t)
tups = cursor.fetchall()
last_tup = (len(tups))
def parse_subpage(number):
    print(f'Pracuje nad linkiem {number}.')
    for tup in tups:
        
        subpage = get(tup).get_text()
        bs = BeautifulSoup(subpage.content, 'html.parser')
        suboffer: object
    for suboffer in bs.find('li', class_='offer-details__item'):
        details = suboffer.find('strong').get_text().strip()

        cursor.execute('''ALTER TABLE offers ADD details TEXT''')
        cursor.execute('UPDATE offers SET details = ?', (details,))

    db.commit()
for subpage in range(1, last_tup):
    parse_subpage(subpage)
db.close()
